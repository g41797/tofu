{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"\"Before machines can work, people must talk.\"    Get Started GitHub Repository"},{"location":"blog/","title":"Blog","text":""},{"location":"mds/ai-usage/","title":"Ai usage","text":"<p>AI was used for assistance in GitHub Pages:</p> <ul> <li>Image Generation</li> <li>Polishing of documentation</li> <li>Help in translation</li> <li>Creation custom css and html files</li> <li>\"Fine-tuning\" of mkdocs.yml</li> <li>Sockets 101 writing (called 101 because 100% AI and 1% me)</li> </ul>"},{"location":"mds/allocator/","title":"Allocator","text":"<p>Zig takes pride in its allocators; they are its \"signature feature,\" or, as one might say, the \"spice of life\".</p> <p>The \"allocator-passing idiom\" in Zig refers to the explicit handling of memory allocation by passing an allocator as a parameter to functions and data structures, empowering the caller to control the allocation strategy at every level of the program.</p> <p>Tofu's relationship with Allocators is similar to Henry Ford's famous quote about car color:</p> <p>\"Customers can have any color they want, so long as it is black.\"</p> <p>Similarly, allocators for Tofu can be anything, provided they are 'GPA compatible'.</p> <p>Allocator names in Zig change often. This reminds me of an old Unix joke:</p> <p>\"Unix is an operating system where nobody knows what the print command is called today\"</p> <p>I'll use GPA (General Purpose Allocator) because I expect that the name GPA will persist in common use.</p> <p> 'GPA compatible' means:</p> <ul> <li>It is thread-safe.</li> <li>Its life cycle is the same as the life cycle of the process.</li> <li>The memory it releases truly allows for further reuse of that released memory.</li> </ul> <p>For example, <code>std.heap.c_allocator</code> satisfies these requirements, but <code>std.heap.ArenaAllocator</code> does not.</p> <p>How many unnecessary memories one Allocator brings back :disappointed: ...</p>"},{"location":"mds/ampe/","title":"Ampe","text":"<p>Async message passing engine(Ampe) or simply the engine is the \"holder\" (owner) and allocator of all tofu resources:</p> <ul> <li>ChannelGroup(s)</li> <li>Message(s))</li> </ul> <p>Consider it the GPA of tofu. </p>"},{"location":"mds/ampe/#ampe-creation","title":"Ampe creation","text":"Example of Ampe creation<pre><code>pub fn createDestroyAmpe(gpa: Allocator) !void {\n    // Create engine implementation object\n    const rtr: *Reactor = try Reactor.Create(gpa, DefaultOptions);\n\n    // Destroy it after return or on error\n    defer rtr.*.Destroy();\n\n    // Create ampe interface\n    const ampe: Ampe = try rtr.*.ampe();\n\n    _ = ampe;\n\n    // No need to destroy ampe itself.\n    // It is an interface provided by Reactor.\n    // It will be destroyed via  rtr.*.Destroy().\n}\n</code></pre> <p>where</p> <ul> <li>gpa is GPA Compatible Allocator</li> <li>DefaultOptions </li> </ul> <p>Note</p> <p>You can create multiple engines per process.</p>"},{"location":"mds/ampe/#interface","title":"Interface","text":"<p>Ampe is represented by the following interface: </p> Brief version of the Interface<pre><code>pub const Ampe = struct {\n    pub fn create(ampe: Ampe) status.AmpeError!ChannelGroup {...}\n    pub fn destroy(ampe: Ampe, chnls: ChannelGroup) status.AmpeError!void {...}\n\n    pub fn get(ampe: Ampe, strategy: AllocationStrategy) status.AmpeError!?*message.Message {...}\n    pub fn put(ampe: Ampe, msg: *?*message.Message) void {...}\n\n    pub fn getAllocator(ampe: Ampe) Allocator {...}\n</code></pre> <p>Just a reminder: all methods are thread-safe.</p> <p>The first two methods, create/destroy, manage a ChannelGroup. You don't need to know what that is yet; just make a note of it.</p> <p>The next two methods require additional explanation, so let's move on to the Message Pool.</p>"},{"location":"mds/ampe/#message-pool","title":"Message Pool","text":"<p>Ampe supports a Message Pool mechanism to improve system performance.</p> <p>The get operation retrieves an existing message from the pool or creates a new one.  The choice is determined by the strategy: AllocationStrategy parameter: <pre><code>pub const AllocationStrategy = enum {\n    poolOnly, // Tries to get a message from the pool. Returns null if the pool is empty.\n    always,   // Gets a message from the pool or creates a new one if the pool is empty.\n};\n</code></pre></p> <p>null isn't error</p> <p>Returned by get null is absolutely valid value, null returned if the pool is empty and the strategy is poolOnly. </p> <p>get returns error if</p> <ul> <li>allocation failed</li> <li>engine performs shutdown</li> </ul> <p>Opposite put operation returns message to the pool and sets it's value to null. If engine performs shutdown or pool is full, message will be destroyed, means all allocated memory silently will be released.</p> <pre><code>    var msg: ?*Message = try ampe.get(tofu.AllocationStrategy.poolOnly);\n    defer ampe.put(&amp;msg);\n</code></pre> <p>Because null returned by get is valid value , it's also valid value for put: if msg == null, put does nothing.</p> <p>NAQ: *?*message.Message - WTH???</p> <p>*?* (address of optional pointer) idiom allows to prevent reusing of released or moved to other thread objects(structs). In our case - Messages.</p> <p><code>ampe.put(&amp;msg)</code>:</p> <ul> <li>returns msg to the pool</li> <li>set msg to null</li> </ul> <p>As result:</p> <ul> <li>every further put will be successful</li> <li>every further attempt to use msg without check will fail</li> </ul> <p>You will see usage of *?* in different places during our journey.</p>"},{"location":"mds/ampe/#pool-configuration","title":"Pool configuration","text":"<p>Pool configuration is determined by  <pre><code>pub const Options = struct {\n    initialPoolMsgs: ?u16 = null,\n    maxPoolMsgs: ?u16 = null,\n};\n</code></pre> initialPoolMsgs - is the number of messages in the pool created during initialization of engine</p> <p>maxPoolMsgs - is the maximal number of the messages </p> <p>Do you remember ? </p> <p>If ... pool is full, message will be destroyed</p> <p>means if number of the messages in the pool == maxPoolMsgs, message will be destroyed.</p> <p>Tofu provides default pool configuration: Just example of configuration, it isn't recommendation<pre><code>    pub const DefaultOptions: Options = .{\n        .initialPoolMsgs = 16,\n        .maxPoolMsgs = 64,\n    };\n</code></pre></p> <p>Pool configuration is used during creation of engine: <pre><code>    // Create engine implementation object with default pool configuration \n    var rtr: *Reactor = try Reactor.Create(gpa, DefaultOptions);\n</code></pre></p> <p>Just clarification - you don't deal with pool destroy, it will be destroyed during destroy of engine. </p>"},{"location":"mds/ampe/#errors-and-statuses","title":"Errors and Statuses","text":"<p>Tofu defines own error set: Partial tofu error set<pre><code>pub const AmpeError = error{\n    NotImplementedYet,\n    WrongConfiguration,\n    NotAllowed,\n    NullMessage,\n    ............\n    PoolEmpty,\n    AllocationFailed,\n    ............\n    ShutdownStarted,\n    ProcessingFailed, \n    UnknownError,\n};\n</code></pre> There is also enumerator for statuses: Partial tofu statuses<pre><code>pub const AmpeStatus = enum(u8) {\n    success = 0,\n    not_implemented_yet,\n    wrong_configuration,\n    not_allowed,\n    null_message,\n    ............\n    pool_empty,\n    allocation_failed,\n    ............\n    shutdown_started,\n    ............\n    processing_failed,\n    unknown_error,\n};\n</code></pre></p> <p>Every AmpeError has corresponding AmpeStatus enumerator (except 'success').</p> <p>Errors and Statuses have self-described names which I hope means I don\u2019t have to describe each one separately.</p> <p>To jump ahead a bit, this system allows errors to be transmitted as part of Message,  using just 1 byte (u8).</p> <p>You can use helper function <code>status.raw_to_error(rs: u8) AmpeError!void</code> in order to convert byte to corresponding error.</p> <p>Not every non-zero status means an error right away. It depends on the situation. For example, 'channel_closed'</p> <ul> <li>is not an error if you requested to close the channel  </li> <li>it is an error if it happens in the middle of communication</li> </ul>"},{"location":"mds/channel-group/","title":"ChannelGroup","text":"<p>ChannelGroup provides full-duplex, asynchronous message exchange between peers. </p> NAQ: Why \"peers\" instead of \"client/server\"? <p>Tofu uses client and server terms to describe the initial handshake. After the handshake, both sides are called peers because they have equal  functionality and roles.</p> <p>Simplest description of ChannelGroup you can get from its name - Group Of Channels :smile:.</p>"},{"location":"mds/channel-group/#channel","title":"Channel","text":"<p>Think of a channel as a virtual socket.</p> <p>There are two kinds of channels:</p> <ul> <li>Listener \u2013 Analog of a listener socket.</li> <li>IO \u2013 Analog of client socket or accepted server socket.</li> </ul> NAQ: Why not just Socket/SocketGroup? <p>You cannot send messages to an unconnected socket, but it ok with channel.</p> <p>Channels are identified by a channel number in the range [1-65534].</p> <p>Two channel number values are reserved:</p> <ul> <li>0 \u2013 Unassigned channel number</li> <li>65535 \u2013 Tofu internal channel number</li> </ul> <p>Channel numbers are unique within the engine that created them, from creation until closure.</p> <p>Warn</p> <p>Another engine in the same process or an engine in a different process may assign the same channel number simultaneously.</p> <p>Every channel has 3 internal states:</p> <ul> <li>opened - engine assigned channel number</li> <li>ready </li> <li>IO channel - ready for send/receive messages</li> <li>Listener channel - ready for accept incoming connections</li> <li>closed</li> </ul>"},{"location":"mds/channel-group/#channelgroup-createdestroy","title":"ChannelGroup create/destroy","text":"<p>Let's create and destroy a ChannelGroup\u2014still without fully understanding what it is.</p> <pre><code>    const rtr: *Reactor = try Reactor.Create(gpa, DefaultOptions);\n    defer rtr.*.Destroy();\n\n    const ampe: Ampe = try rtr.*.ampe();\n\n    const chnls: ChannelGroup = try ampe.create();\n\n    defer { \n        _ = ampe.destroy(chnls) catch | err | {\n            std.log.err(\"destroy channel group failed with error {any}\", .{err});\n        };\n    }\n</code></pre> <p>There are two ways to release resources (messages, channels etc.) of ChannelGroup</p> <ul> <li>explicit - via  ampe.destroy(...) [PREFERRED]</li> <li>implicit - during destroy of engine - rtr.*.Destroy() [FOR SIMPLE GO/NO GO]</li> </ul> <p>Warn</p> <p>ampe.destroy(chngrp) cannot be used directly in defer because defer does not allow try or error unions.  </p>"},{"location":"mds/channel-group/#channelgroup-interface","title":"ChannelGroup interface","text":"<pre><code>/// Defines the ChannelGroup interface for async message passing.\n/// Supports two-way message exchange between peers.\npub const ChannelGroup = struct {\n\n    /// Submits a message for async processing:\n    /// - most cases: send to peer\n    /// - others: internal network related processing\n    ///\n    /// On success:\n    /// - Sets `msg.*` to null (prevents reuse).\n    /// - Returns `BinaryHeader` for tracking.\n    ///\n    /// On error:\n    /// - Returns an error.\n    /// - If the engine cannot use the message (internal failure),\n    ///   also sets `msg.*` to null.\n    ///\n    /// Thread-safe.\n    pub fn enqueueToPeer(\n        chnls: ChannelGroup,\n        msg: *?*message.Message,\n    ) status.AmpeError!message.BinaryHeader {...}\n\n    /// Waits for the next message from the internal queue.\n    ///\n    /// Timeout is in nanoseconds. Returns `null` if no message arrives in time.\n    ///\n    /// Message sources:\n    /// - Remote peer (via `enqueueToPeer` on their side).\n    /// - Application (via `updateReceiver` on this ChannelGroup).\n    /// - Ampe (status/control messages).\n    ///\n    /// Check `BinaryHeader` to identify the source.\n    ///\n    /// On error: stop using this ChannelGroup and call `ampe.destroy` on it.\n    ///\n    /// Call in a loop from **one thread only**.\n    pub fn waitReceive(\n        chnls: ChannelGroup,\n        timeout_ns: u64,\n    ) status.AmpeError!?*message.Message {...}\n\n    /// Adds a message to the internal queue for `waitReceive`.\n    ///\n    /// If `msg.*` is not null:\n    /// - Engine sets status to `'receiver_update'`.\n    /// - Sets `msg.*` to null after success.\n    /// - No need for `channel_number` or similar fields.\n    ///\n    /// If `msg.*` is null:\n    /// - Creates a `'receiver_update'` Signal and adds it.\n    ///\n    /// Returns error if shutting down.\n    ///\n    /// Use from another thread to:\n    /// - Wake the receiver (`msg.*` = null).\n    /// - Send info/commands/notifications.\n    ///\n    /// FIFO order only. No priority queues.\n    ///\n    /// Thread-safe.\n    pub fn updateReceiver(\n        chnls: ChannelGroup,\n        update: *?*message.Message,\n    ) status.AmpeError!void {...}\n}\n</code></pre> <p>Caller of every function/method has \"non-formal\" role:</p> <ul> <li>enqueueToPeer caller \u2192 Producer</li> <li>waitReceive caller \u2192 Consumer</li> <li>updateReceiver caller \u2192 Notifier</li> </ul> NAQ: No methods use channel numbers. How to handle channels? <p>You also won't see IP addresses or port numbers. All this info is in the messages.</p> <p>Without details about Message, it is hard to explain how to use this interface. A full description will come later.</p>"},{"location":"mds/coding-style/","title":"Coding style","text":""},{"location":"mds/coding-style/#big-endian-imports-vs-little-endian-imports","title":"Big-endian imports vs Little-endian imports","text":"<p>There are two \"parties\" in Zig about where imports should be placed.</p> <p>Big-endian - imports are placed at the top of the file, before the code.</p> <p>Little-endian - imports are placed at the bottom of the file, after the code.</p> <p>I belong to the LE party. At least, tofu sources use LE imports.</p> <p>But in examples, I am using BE just for your convenience.</p>"},{"location":"mds/coding-style/#type-inference","title":"Type inference","text":"<p>Type inference is convenient for the developer:</p> <ul> <li>when working with comptime-generated code</li> <li>when the IDE displays the actual types</li> </ul> <p>It is not convenient for the reader:</p> <ul> <li>when looking at small examples or snippets</li> <li>when reading code in a browser or editor without type hints</li> </ul> <p>That\u2019s why in examples \u2014 and increasingly in my own projects \u2014 I try to avoid type inference.</p>"},{"location":"mds/coding-style/#automatic-dereference-for-the-operator-on-single-pointers","title":"Automatic dereference for the <code>.</code> operator on single pointers","text":"<p>I am slowly moving toward always dereference explicitly.</p>"},{"location":"mds/configurators/","title":"Configurators","text":""},{"location":"mds/conversation/","title":"Conversation","text":""},{"location":"mds/conversation/#context","title":"Context","text":"<p>This document captures a technical conversation between two developers designing a Print Server system using the tofu messaging framework.  This exemplifies tofu's core philosophy: development starts with a conversation between developers, not with API specifications.</p> <p>Participants:</p> <ul> <li>S (Spool Server Developer): Manages print job queue and distribution</li> <li>R (RIP Worker Process Developer): Performs Raster Image Processing on print jobs</li> </ul>"},{"location":"mds/conversation/#the-conversation","title":"The Conversation","text":"<p>This is the technical conversation that defines the entire protocol. Notice how natural message flow emerges from developer discussion rather than formal API design.</p> <pre><code>S: I don't know the addresses of the workers, so you should connect to me.\n\nR: I'll send a HelloRequest, because the worker can process only specific PDL types,\n   the PDL header will contain either PS or PDF.\n\nS: Do I need to send you a HelloResponse?\n\nR: No, just start sending me messages with PDL data.\n\nS: As signals?\n\nR: No, as multi-requests \u2014 each with a message ID equal to the job ID.\n\nS: You forgot the Job Ticket.\n\nR: Right. The first request should have a JobTicket header (JDF or PPD) and the\n   ticket data in the body. The following requests will have the PDL header\n   (PDF or PS) with the related content.\n\nS: But JDF is usually used only for PDF...\n\nR: Yes, but let's keep it flexible.\n\nS: Can you process several jobs simultaneously?\n\nR: It depends on licensing. Anyway, if I can, I'll send another HelloRequest \u2014\n   working one job per channel looks cleaner.\n\nS: I need a progress indicator.\n\nR: No problem. I'll send signals with the same message ID \u2014 the Progress header\n   will show the range [N:M] for page numbers.\n\nS: On job finish, send me a Response with the same message ID and processing status.\n   Also include the Progress header.\n\nR: Why should I send an obsolete message? Are you expecting a graceful close?\n\nS: Of course.\n\nR: Then I'll send a ByeRequest with the same information, and you'll send me a\n   ByeResponse. After that, I'll abort the connection immediately.\n\nS: That's enough for today. Send me a short text file with this protocol \u2014\n   I'll save it in Git.\n\nR: Deal. How about a cup of coffee?\n</code></pre>"},{"location":"mds/conversation/#protocol-analysis","title":"Protocol Analysis","text":""},{"location":"mds/conversation/#key-decisions-made","title":"Key Decisions Made","text":"Decision Rationale R connects to S S doesn't know worker addresses upfront PDL type in HelloRequest Workers are specialized (PS or PDF only) No HelloResponse Streamlined - S just starts sending jobs Multi-requests with job_id All chunks of one job share same message_id JobTicket first, then PDL Job metadata separate from actual data One job per channel Clean separation, easier state management Progress as signals One-way updates, no response needed ByeRequest for completion Graceful close with final status"},{"location":"mds/conversation/#message-types-defined","title":"Message Types Defined","text":"<ol> <li>HelloRequest - Worker announces capabilities (PDL: PS or PDF)</li> <li>JobTicket Request - First request with job metadata (JDF/PPD)</li> <li>PDL Data Requests - Subsequent requests with actual print data</li> <li>Progress Signals - Status updates during processing</li> <li>ByeRequest - Job completion with final status</li> <li>ByeResponse - Server acknowledges completion</li> </ol>"},{"location":"mds/conversation/#communication-diagrams","title":"Communication Diagrams","text":""},{"location":"mds/conversation/#diagram-1-connection-establishment","title":"Diagram 1: Connection Establishment","text":"<pre><code>sequenceDiagram\n    participant S as Spool Server\n    participant R as RIP Worker\n\n    Note over S: Server starts listening\n    S-&gt;&gt;S: WelcomeRequest (TCP, port)\n    Note over S: Listening on port\n\n    Note over R: Worker knows server address\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PS or PDF\n    Note over R,S: No HelloResponse!&lt;br/&gt;S just starts sending jobs\n\n    Note over S,R: Connection established&lt;br/&gt;Channel assigned (e.g., ch=123)</code></pre> <p>Key Points: - S (Server) creates listener via WelcomeRequest - R (Worker) connects and sends HelloRequest with PDL capability - No HelloResponse - streamlined connection - Channel number assigned for this connection</p>"},{"location":"mds/conversation/#diagram-2-single-job-processing-flow","title":"Diagram 2: Single Job Processing Flow","text":"<pre><code>sequenceDiagram\n    participant S as Spool Server\n    participant R as RIP Worker\n\n    Note over S: Job arrives (job_id=1001)\n\n    S-&gt;&gt;R: Request (ch=123, mid=1001, more=expected)&lt;br/&gt;JobTicket: JDF&lt;br/&gt;Body: [job ticket data]\n    Note over R: Parse job ticket&lt;br/&gt;Prepare for PDL data\n\n    S-&gt;&gt;R: Request (ch=123, mid=1001, more=expected)&lt;br/&gt;PDL: PDF&lt;br/&gt;Body: [PDF chunk 1]\n    Note over R: Process chunk 1\n\n    S-&gt;&gt;R: Request (ch=123, mid=1001, more=expected)&lt;br/&gt;PDL: PDF&lt;br/&gt;Body: [PDF chunk 2]\n    Note over R: Process chunk 2\n\n    R-&gt;&gt;S: Signal (ch=123, mid=1001)&lt;br/&gt;Progress: [2:10]\n    Note over S: Worker processed 2 of 10 pages\n\n    S-&gt;&gt;R: Request (ch=123, mid=1001, more=last)&lt;br/&gt;PDL: PDF&lt;br/&gt;Body: [PDF chunk 3 - final]\n    Note over R: Process final chunk\n\n    R-&gt;&gt;S: Signal (ch=123, mid=1001)&lt;br/&gt;Progress: [10:10]\n    Note over S: All pages processed\n\n    R-&gt;&gt;S: ByeRequest (ch=123, mid=1001)&lt;br/&gt;Status: Success&lt;br/&gt;Progress: [10:10]\n    S-&gt;&gt;R: ByeResponse (ch=123, mid=1001)\n\n    Note over R: Abort connection&lt;br/&gt;Job complete</code></pre> <p>Key Points: - All messages for one job use same message_id (job_id) - First request: JobTicket header + ticket data - Subsequent requests: PDL header + PDL data chunks - <code>more</code> flag: <code>.expected</code> until last chunk (<code>.last</code>) - Progress signals: Fire-and-forget updates [current:total] - ByeRequest/ByeResponse: Graceful close with final status</p>"},{"location":"mds/conversation/#diagram-3-multi-job-processing-multiple-channels","title":"Diagram 3: Multi-Job Processing (Multiple Channels)","text":"<pre><code>sequenceDiagram\n    participant S as Spool Server\n    participant R as RIP Worker\n\n    Note over R: Worker can handle multiple jobs&lt;br/&gt;(licensing permits)\n\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PDF\n    Note over S,R: Channel 123 assigned\n\n    S-&gt;&gt;R: Request (ch=123, mid=1001)&lt;br/&gt;JobTicket: JDF&lt;br/&gt;[Job 1 ticket]\n    S-&gt;&gt;R: Request (ch=123, mid=1001)&lt;br/&gt;PDL: PDF&lt;br/&gt;[Job 1 data...]\n\n    Note over R: Job 1 processing started\n\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PDF\n    Note over S,R: Channel 456 assigned&lt;br/&gt;(new channel for new job)\n\n    S-&gt;&gt;R: Request (ch=456, mid=2002)&lt;br/&gt;JobTicket: JDF&lt;br/&gt;[Job 2 ticket]\n    S-&gt;&gt;R: Request (ch=456, mid=2002)&lt;br/&gt;PDL: PDF&lt;br/&gt;[Job 2 data...]\n\n    Note over R: Job 2 processing started&lt;br/&gt;Jobs run in parallel\n\n    R-&gt;&gt;S: Signal (ch=123, mid=1001)&lt;br/&gt;Progress: [5:10]\n    Note over S: Job 1 progress update\n\n    R-&gt;&gt;S: Signal (ch=456, mid=2002)&lt;br/&gt;Progress: [3:8]\n    Note over S: Job 2 progress update\n\n    R-&gt;&gt;S: ByeRequest (ch=123, mid=1001)&lt;br/&gt;Status: Success\n    S-&gt;&gt;R: ByeResponse (ch=123, mid=1001)\n    Note over R: Job 1 complete, ch=123 closed\n\n    R-&gt;&gt;S: ByeRequest (ch=456, mid=2002)&lt;br/&gt;Status: Success\n    S-&gt;&gt;R: ByeResponse (ch=456, mid=2002)\n    Note over R: Job 2 complete, ch=456 closed</code></pre> <p>Key Points: - Worker sends multiple HelloRequests for parallel jobs - Each job gets its own channel (clean separation) - Channel 123 handles job_id=1001 - Channel 456 handles job_id=2002 - Jobs processed independently - Each channel closed via ByeRequest/ByeResponse</p>"},{"location":"mds/conversation/#diagram-4-complete-lifecycle-with-error-handling","title":"Diagram 4: Complete Lifecycle with Error Handling","text":"<pre><code>sequenceDiagram\n    participant S as Spool Server\n    participant R as RIP Worker\n\n    Note over S: Server startup\n    S-&gt;&gt;S: WelcomeRequest (TCP:9000)\n    Note over S: Listening on port 9000\n\n    Note over R: Worker startup\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PS\n    Note over S,R: Channel 101 assigned\n\n    rect rgb(200, 255, 200)\n        Note over S,R: SUCCESSFUL JOB\n        S-&gt;&gt;R: Request (ch=101, mid=5001)&lt;br/&gt;JobTicket: PPD&lt;br/&gt;[PostScript job ticket]\n        S-&gt;&gt;R: Request (ch=101, mid=5001)&lt;br/&gt;PDL: PS&lt;br/&gt;[PostScript data]\n        R-&gt;&gt;S: Signal (ch=101, mid=5001)&lt;br/&gt;Progress: [1:1]\n        R-&gt;&gt;S: ByeRequest (ch=101, mid=5001)&lt;br/&gt;Status: Success&lt;br/&gt;Progress: [1:1]\n        S-&gt;&gt;R: ByeResponse (ch=101, mid=5001)\n        Note over R: Close channel 101\n    end\n\n    Note over R: Ready for next job\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PS\n    Note over S,R: Channel 102 assigned\n\n    rect rgb(255, 200, 200)\n        Note over S,R: FAILED JOB\n        S-&gt;&gt;R: Request (ch=102, mid=5002)&lt;br/&gt;JobTicket: PPD&lt;br/&gt;[Job ticket]\n        S-&gt;&gt;R: Request (ch=102, mid=5002)&lt;br/&gt;PDL: PS&lt;br/&gt;[Corrupted data]\n        Note over R: Error: Invalid PostScript\n        R-&gt;&gt;S: ByeRequest (ch=102, mid=5002)&lt;br/&gt;Status: ProcessingFailed&lt;br/&gt;Progress: [0:5]\n        S-&gt;&gt;R: ByeResponse (ch=102, mid=5002)\n        Note over R: Close channel 102\n    end\n\n    Note over R: Worker continues running\n    R-&gt;&gt;S: HelloRequest (ch=0)&lt;br/&gt;PDL: PDF\n    Note over S,R: Channel 103 assigned&lt;br/&gt;(ready for next job)</code></pre> <p>Key Points: - Worker lifecycle spans multiple jobs - Successful job: Status=Success in ByeRequest - Failed job: Status=ProcessingFailed (or other error) - Progress header shows how far processing got - Worker remains connected, ready for next job - Each job gets fresh channel via new HelloRequest</p>"},{"location":"mds/conversation/#diagram-5-message-structure-details","title":"Diagram 5: Message Structure Details","text":"<pre><code>graph TD\n    subgraph \"HelloRequest Message\"\n        H1[BinaryHeader&lt;br/&gt;ch=0, mtype=hello&lt;br/&gt;role=request]\n        H2[TextHeader&lt;br/&gt;PDL: PS or PDF]\n        H3[Body: empty]\n    end\n\n    subgraph \"JobTicket Request\"\n        J1[BinaryHeader&lt;br/&gt;ch=123, mtype=regular&lt;br/&gt;role=request&lt;br/&gt;mid=1001, more=expected]\n        J2[TextHeader&lt;br/&gt;JobTicket: JDF or PPD]\n        J3[Body: job ticket data]\n    end\n\n    subgraph \"PDL Data Request\"\n        P1[BinaryHeader&lt;br/&gt;ch=123, mtype=regular&lt;br/&gt;role=request&lt;br/&gt;mid=1001, more=expected/last]\n        P2[TextHeader&lt;br/&gt;PDL: PDF or PS]\n        P3[Body: PDL data chunk]\n    end\n\n    subgraph \"Progress Signal\"\n        G1[BinaryHeader&lt;br/&gt;ch=123, mtype=regular&lt;br/&gt;role=signal&lt;br/&gt;mid=1001]\n        G2[TextHeader&lt;br/&gt;Progress: N:M]\n        G3[Body: empty or details]\n    end\n\n    subgraph \"ByeRequest Message\"\n        B1[BinaryHeader&lt;br/&gt;ch=123, mtype=bye&lt;br/&gt;role=request&lt;br/&gt;mid=1001]\n        B2[TextHeader&lt;br/&gt;Progress: N:M&lt;br/&gt;Status: app-specific]\n        B3[Body: final status data]\n    end</code></pre>"},{"location":"mds/conversation/#protocol-summary","title":"Protocol Summary","text":""},{"location":"mds/conversation/#message-flow-patterns","title":"Message Flow Patterns","text":"<p>Pattern 1: Connection <pre><code>Worker \u2192 Server: HelloRequest (PDL capability)\n[No response - Server just starts sending]\n</code></pre></p> <p>Pattern 2: Job Submission (Multi-Request) <pre><code>Server \u2192 Worker: Request (JobTicket + ticket data, mid=job_id, more=expected)\nServer \u2192 Worker: Request (PDL + data chunk 1, mid=job_id, more=expected)\nServer \u2192 Worker: Request (PDL + data chunk 2, mid=job_id, more=expected)\n...\nServer \u2192 Worker: Request (PDL + data chunk N, mid=job_id, more=last)\n</code></pre></p> <p>Pattern 3: Progress Updates (Signals) <pre><code>Worker \u2192 Server: Signal (Progress: [current:total], mid=job_id)\nWorker \u2192 Server: Signal (Progress: [current:total], mid=job_id)\n...\n</code></pre></p> <p>Pattern 4: Job Completion (Graceful Close) <pre><code>Worker \u2192 Server: ByeRequest (Status + Progress, mid=job_id)\nServer \u2192 Worker: ByeResponse (mid=job_id)\n[Worker closes connection]\n</code></pre></p>"},{"location":"mds/conversation/#headers-dictionary","title":"Headers Dictionary","text":""},{"location":"mds/conversation/#headers-used-in-this-protocol","title":"Headers Used in This Protocol","text":"Header Values Usage Message Types PDL <code>PS</code>, <code>PDF</code> Page Description Language type HelloRequest, PDL Requests JobTicket <code>JDF</code>, <code>PPD</code> Job ticket format First Request per job Progress <code>[N:M]</code> Current page : Total pages Signals, ByeRequest Status Application-defined Job processing result ByeRequest (in body or header)"},{"location":"mds/conversation/#message-id-strategy","title":"Message ID Strategy","text":"<ul> <li>message_id = job_id for all messages related to one job</li> <li>Enables correlation: all chunks, progress updates, and completion share same ID</li> <li>Example: Job 1001 uses mid=1001 throughout its lifecycle</li> </ul>"},{"location":"mds/conversation/#design-insights","title":"Design Insights","text":""},{"location":"mds/conversation/#why-this-conversation-matters","title":"Why This Conversation Matters","text":"<p>This conversation demonstrates tofu's core philosophy:</p> <ol> <li>Natural Protocol Evolution:</li> <li>Started with basic connection (\"you should connect to me\")</li> <li>Evolved through discussion (multi-requests, job tickets, progress)</li> <li> <p>Refined with experience (\"JDF is usually only for PDF\" \u2192 \"let's keep it flexible\")</p> </li> <li> <p>Developer-Driven Design:</p> </li> <li>No formal specification written first</li> <li>Protocol emerged from understanding requirements</li> <li> <p>Both developers contributed to shape the flow</p> </li> <li> <p>Flexibility Over Rigidity:</p> </li> <li>\"Let's keep it flexible\" - design for change</li> <li>Multi-channel support added mid-conversation</li> <li> <p>Progress updates added when need identified</p> </li> <li> <p>Message-as-Cube Approach:</p> </li> <li>Each message type is a building block</li> <li>Combine HelloRequest + JobTicket + PDL Requests + Signals + ByeRequest</li> <li>Result: Complete print job processing workflow</li> </ol>"},{"location":"mds/conversation/#translation-to-code","title":"Translation to Code","text":"<p>After this conversation, developers can:</p> <ol> <li> <p>Write Protocol Documentation: (Simple text file for Git)    <pre><code>PROTOCOL: Spool Server \u2194 RIP Worker\n\n1. Worker \u2192 Server: HelloRequest, PDL: PS|PDF\n2. Server \u2192 Worker: Multi-requests (job_id)\n   - First: JobTicket: JDF|PPD, body: ticket\n   - Rest: PDL: PS|PDF, body: data chunks\n3. Worker \u2192 Server: Signals, Progress: [N:M]\n4. Worker \u2192 Server: ByeRequest, Status + Progress\n5. Server \u2192 Worker: ByeResponse\n</code></pre></p> </li> <li> <p>Implement Using Tofu:</p> </li> <li>Use tofu's Message structure</li> <li>Configure TCP server/client</li> <li>Implement message handlers</li> <li> <p>No complex code generation needed</p> </li> <li> <p>Iterate Quickly:</p> </li> <li>Test with real data</li> <li>Adjust headers as needed</li> <li>Add new message types if requirements change</li> </ol>"},{"location":"mds/conversation/#comparison-with-traditional-approaches","title":"Comparison with Traditional Approaches","text":""},{"location":"mds/conversation/#api-first-grpc-rest-approach","title":"API-First (gRPC, REST) Approach","text":"<pre><code>// Would require formal IDL\nservice PrintServer {\n  rpc SubmitJob(JobRequest) returns (JobResponse);\n  rpc StreamPDL(stream PDLChunk) returns (stream Progress);\n  rpc GetStatus(JobID) returns (JobStatus);\n}\n\nmessage JobRequest {\n  string job_ticket_format = 1;  // JDF or PPD\n  bytes job_ticket = 2;\n  string pdl_type = 3;           // PS or PDF\n}\n\nmessage PDLChunk {\n  int64 job_id = 1;\n  bytes data = 2;\n  bool is_last = 3;\n}\n\n// ... more formal definitions\n</code></pre> <p>Problems: - Requires IDL file before coding - Code generation step needed - Changes require regeneration - Versioning complexity - Lost flexibility</p>"},{"location":"mds/conversation/#tofu-message-first-approach","title":"Tofu (Message-First) Approach","text":"<pre><code>Conversation \u2192 Text Protocol \u2192 Implementation\n- No IDL needed\n- No code generation\n- Direct implementation\n- Easy to change\n- Full flexibility\n</code></pre> <p>Advantages: - Start coding immediately after conversation - Protocol is the documentation - Changes are simple (add headers, adjust messages) - Natural evolution based on real usage</p>"},{"location":"mds/conversation/#lessons-for-protocol-design","title":"Lessons for Protocol Design","text":""},{"location":"mds/conversation/#from-this-conversation","title":"From This Conversation","text":"<ol> <li>Start with Connection Pattern:</li> <li>Who connects to whom?</li> <li> <p>What capabilities need to be announced?</p> </li> <li> <p>Identify Message Roles:</p> </li> <li>Requests that expect responses</li> <li>Signals for one-way notifications</li> <li> <p>Multi-message sequences (job chunks)</p> </li> <li> <p>Use Headers for Metadata:</p> </li> <li>PDL type (PS/PDF)</li> <li>Job ticket format (JDF/PPD)</li> <li> <p>Progress indicators ([N:M])</p> </li> <li> <p>Leverage Message ID:</p> </li> <li>Correlation across multi-message flows</li> <li> <p>Business transaction ID (job_id = message_id)</p> </li> <li> <p>Design for Lifecycle:</p> </li> <li>Connection establishment (Hello)</li> <li>Data exchange (Requests/Signals)</li> <li> <p>Graceful termination (Bye)</p> </li> <li> <p>Plan for Scale:</p> </li> <li>Multiple channels for parallel processing</li> <li>Clean separation (one job per channel)</li> </ol>"},{"location":"mds/conversation/#next-steps-for-developers","title":"Next Steps for Developers","text":"<p>After this conversation, S and R would:</p> <ol> <li>Write Brief Protocol Doc: (Save in Git)</li> <li>Copy conversation or summary</li> <li>Add message format details</li> <li> <p>Document headers</p> </li> <li> <p>Create Test Scenarios:</p> </li> <li>Single job end-to-end</li> <li>Multi-job parallel processing</li> <li> <p>Error handling (corrupted PDL)</p> </li> <li> <p>Implement Incrementally:</p> </li> <li>Basic connection first</li> <li>Single job flow</li> <li>Progress updates</li> <li> <p>Multi-job support</p> </li> <li> <p>Iterate Based on Reality:</p> </li> <li>Discover edge cases</li> <li>Adjust message flow</li> <li>Add new headers as needed</li> </ol>"},{"location":"mds/conversation/#conclusion","title":"Conclusion","text":"<p>This conversation exemplifies tofu's philosophy:</p> <p>\"Connect your developers. Then connect your applications.\"</p> <p>The protocol emerged naturally from: - Understanding requirements (print job processing) - Developer expertise (PDL types, job tickets) - Practical constraints (unknown worker addresses) - Refinement through discussion (progress updates, graceful close)</p> <p>Result: A working protocol defined in 15 lines of conversation, implemented with simple message passing, flexible enough to evolve.</p> <p>No API specs. No code generation. No framework lock-in. Just messages flowing between peers.</p>"},{"location":"mds/features/","title":"Features","text":"<ul> <li>Message-Based: Uses discrete messages for communication.</li> <li>Asynchronous: Enables non-blocking message exchanges.</li> <li>Duplex: Supports two-way communication.</li> <li>Peer-to-Peer: Allows equal roles after connection establishment.</li> <li>Stream oriented transport - TCP/IP and Unix Domain Sockets</li> <li>Multithread-friendly - All APIs are safe for concurrent access.</li> <li>Memory management for messages - Internal message pool</li> <li>Backpressure management - Allows to control receive of messages</li> <li>Customizable application flows - Allows to build various application flows not restricted to request/response or pub/sub</li> <li>Simplest API - You don't have to bother with or know the \"guts\" of socket interfaces</li> <li>DIY - No enforced authentication or serialization; provides features to design and implement your own.</li> <li>Callback enabled - This will be explained later. </li> </ul>"},{"location":"mds/imports/","title":"Imports","text":"<p>All examples assume that the snippet below is added to your code.</p> <pre><code>const std = @import(\"std\");\nconst log = std.log;\nconst Allocator = std.mem.Allocator;\nconst assert = std.debug.assert;\n\nconst testing = std.testing;\n\n// Import of module 'tofu'\npub const tofu = @import(\"tofu\");\n\n// Reactor: The single-threaded, event-driven implementation\n// of the Ampe interface. It utilizes the Reactor pattern to multiplex\n// non-blocking socket I/O via an internal poll-style loop.\npub const Reactor = tofu.Reactor;\n\npub const Ampe = tofu.Ampe;\n\n// Contains settings for the internal message pool.\npub const Options = tofu.Options;\n\n// The default configuration options for the pool.\npub const DefaultOptions = tofu.DefaultOptions;\n\n// A grouping mechanism for managing a collection of related channels.\npub const ChannelGroup = tofu.ChannelGroup;\n\npub const message = tofu.message;\n\n// The core Message structure processed by the engine.\npub const Message = tofu.Message;\n\n// Meta-data for the Message.\n// Used internally by the engine for routing and by the application for context.\npub const BinaryHeader = message.BinaryHeader;\n\npub const status = tofu.status;\n// An enum representation of the status byte\n// (part of BinaryHeader) for clear status tracking.\npub const AmpeStatus = status.AmpeStatus;\n// An error type corresponding to the status above,\n// used for conveying failure states.\npub const AmpeError = status.AmpeError;\n\n// Helpers - for convenient injection of socket addresses\n// to the message.\npub const configurator = tofu.configurator;\npub const Configurator = configurator.Configurator;\n</code></pre> <p>And don't forget to assign suitable allocator, e.g.: <pre><code>    var dbalctr = std.heap.DebugAllocator(.{}).init;\n    defer {\n        const deinit_status = dbalctr.deinit();\n        // fail test; can't try in defer as defer is executed after we return\n        if (deinit_status == .leak) {\n            std.log.err(\"memory leak detected\", .{});\n        }\n    }\n\n    const gpa: Allocator = dbalctr.allocator();\n</code></pre></p>"},{"location":"mds/installation/","title":"Installation","text":"<p>Add tofu to build.zig.zon: <pre><code>zig fetch --save git+https://github.com/g41797/tofu\n</code></pre></p> <p>Add tofu to build.zig:</p> Add dependency<pre><code>    const tofu: *build.Dependency = b.dependency(\"tofu\", .{\n        .target = target,\n        .optimize = optimize,\n    });\n</code></pre> <p>For any xyz_mod module that uses tofu, add the following code<pre><code>    xyz_mod.addImport(\"tofu\", tofu.module(\"tofu\"));\n</code></pre> Import tofu<pre><code>pub const tofu = @import(\"tofu\");\n</code></pre></p>"},{"location":"mds/key-ingredients/","title":"Key ingredients","text":"<p>Tofu has only three main ingredients:</p> <ul> <li>Ampe \u2014 the Async Message Passing Engine (we call it the engine).</li> <li>ChannelGroup</li> <li>Message</li> </ul> <p>Each ingredient depends on the others, so it\u2019s hard to explain one without understanding the rest. Because of that, the short descriptions below give only the basic idea.</p> <p>The examples later will help you understand how tofu really works.</p>"},{"location":"mds/key-ingredients/#separation-of-concerns","title":"Separation of Concerns","text":""},{"location":"mds/key-ingredients/#logical-separation","title":"Logical Separation","text":"<p>The Engine owns all resources in Tofu software. It allocates and destroys Message(s) and ChannelGroup(s).</p> <p>The ChannelGroup handles async, two-way exchange of Messages.</p> <p>The Message does two things:</p> <ul> <li>Holds business data and metadata.</li> <li>Works as a command for Tofu.</li> </ul>"},{"location":"mds/key-ingredients/#physical-separation","title":"Physical Separation","text":"<p>The Engine name shows the real work it does. Every engine runs one internal thread with a poll loop. This loop handles all socket operations.</p> <p>The Ampe interface is implemented by the Reactor structure.</p> <p>All ChannelGroups share one internal socket to talk to the engine thread.</p> <p>Each ChannelGroup uses an internal queue for messages (from engine or application).</p> <p>The ChannelGroup is a thin layer. It forwards messages between application and engine thread.</p>"},{"location":"mds/key-ingredients/#tofu-based-communication-flow","title":"Tofu-based Communication Flow","text":"<p>The steps below show how communication works between network participants, called peers:</p> <ul> <li>Initialization: The peer creates a Reactor to get the Ampe interface.</li> <li>Channel Setup: The peer creates a ChannelGroup to manage channels (connections to other peers).</li> <li>Core Loop: In the main application loop, the peer:</li> <li>Sends: Gets Messages from Ampe, fills data, enqueues via ChannelGroup.</li> <li>Receives: Gets and processes incoming messages from other peers.</li> </ul> <p>This is a simple overview. Later sections show full logic and message lifecycle.</p>"},{"location":"mds/naq/","title":"NAQ","text":"<p>What's NAQ?</p> <p>I always wondered why even if the program is not used by anyone, there is still a FAQ section. Even if a question was asked once, why 'frequently'? That's why I use a more honest name: NAQ - Never Asked Questions. I ask myself. I answer myself. You didn't ask. Not even about NAQ.</p> <p>You will see 'NAQ' sections in different places throughout this documentation. I hope they will help clarify the content of the documentation.</p>"},{"location":"mds/overview/","title":"Overview","text":"<p>tofu is a protocol and an asynchronous Zig messaging library used to:</p> <ul> <li>Build custom communication flows.</li> <li>Create non-blocking systems.</li> <li>Enable peer-to-peer messaging between applications.</li> </ul> <p>tofu is a completely new project. It is not a port of old code, and it does not use any C libraries. It is built 100% in native Zig. The core functionality uses only the standard library.</p>"},{"location":"mds/overview/#why-tofu","title":"Why tofu?","text":"<p>As a food, tofu is very simple and has almost no flavor on its own. By using tofu cubes, you can:</p> <ul> <li>Eat it plain for a simple snack.</li> <li>Add a little spice to make it better.</li> <li>Create a culinary masterpiece.</li> </ul> <p>As a protocol, tofu uses messages like cubes. By \"cooking\" these messages together, you can grow your project:</p> <ul> <li>Start with minimal setups.</li> <li>Build complex flows.</li> <li>Create full distributed applications.</li> </ul> <p>Remember</p> <p>tofu is as good as you are a cook.</p>"},{"location":"mds/overview/#a-bit-of-history","title":"A Bit of History","text":"<p>tofu did not come from nowhere.</p> <p>The journey began in 2008 when I first built a similar system. I maintained and ran that system for many years in high-stakes environments. It powered everything from basic IPC to complex data transfers in a custom distributed file system.</p> <p>I left that project a few years ago, but I haven't heard any complaints yet \u2014 the systems are still running strong.</p> <p>Corporate lawyers can stay calm: I didn't take any code. I only took the \"smell.\" (See the precedent case about paying for a smell).</p> <p>By \"smell,\" I mean the core philosophy:</p> <ul> <li>The Message is the API: The data itself defines the connection.</li> <li>Gradual Evolution: Start with something simple and grow it into a powerful system over time.</li> <li>The Mantra: \"Connect your developers. Then connect your applications.\"</li> </ul>"},{"location":"mds/overview/#connect-your-developers-then-connect-your-applications","title":"\"Connect your developers. Then connect your applications.\"","text":"<p>This tofu mantra is a paraphrase of Conway's Law.</p> <p>tofu \"expects\" that development starts with a conversation (connection) similar to the one shown below.</p> <p>Context:</p> <ul> <li>Two developers are discussing the message flow for a new Print Server.</li> <li>The first one is the Spool Server developer (S).</li> <li>The second one develops the RIP Worker Process (R).</li> <li>Don\u2019t worry \u2014 RIP means Raster Image Processing, not what you might think.</li> <li>Some terms may be unknown \u2014 that\u2019s fine. These two know exactly what they mean.</li> </ul> <p>This dialog is shown without the usual jokes or side comments common in real programmer discussions \u2014 just the technical part.</p> <pre><code>S: I don't know the addresses of the workers, so you should connect to me.\n\nR: I'll send a HelloRequest, because the worker can process only specific PDL types,\n   the PDL header will contain either PS or PDF.\n\nS: Do I need to send you a HelloResponse?\n\nR: No, just start sending me messages with PDL data.\n\nS: As signals?\n\nR: No, as multi-requests \u2014 each with a message ID equal to the job ID.\n\nS: You forgot the Job Ticket.\n\nR: Right. The first request should have a JobTicket header (JDF or PPD) and the\n   ticket data in the body. The following requests will have the PDL header\n   (PDF or PS) with the related content.\n\nS: But JDF is usually used only for PDF...\n\nR: Yes, but let's keep it flexible.\n\nS: Can you process several jobs simultaneously?\n\nR: It depends on licensing. Anyway, if I can, I'll send another HelloRequest \u2014\n   working one job per channel looks cleaner.\n\nS: I need a progress indicator.\n\nR: No problem. I'll send signals with the same message ID \u2014 the Progress header\n   will show the range [N:M] for page numbers.\n\nS: On job finish, send me a Response with the same message ID and processing status.\n   Also include the Progress header.\n\nR: Why should I send an obsolete message? Are you expecting a graceful close?\n\nS: Of course.\n\nR: Then I'll send a ByeRequest with the same information, and you'll send me a\n   ByeResponse. After that, I'll abort the connection immediately.\n\nS: That's enough for today. Send me a short text file with this protocol \u2014\n   I'll save it in Git.\n\nR: Deal. How about a cup of coffee?\n</code></pre> <p>I hope you got the point without long smart descriptions or advertising.</p>"},{"location":"mds/overview/#credits","title":"Credits","text":"<ul> <li>Karl Seguin \u2014 for introducing me to Zig networking</li> <li>Franck Blettner \u2014 for creating the template repository for documentation sites, which this documentation is based on </li> <li>Zig Community Forums (in order of my registration) - for your help and patience with my posts<ul> <li>Zig on Reddit</li> <li>Zig on Discord</li> <li>Zig on Discourse</li> </ul> </li> </ul>"},{"location":"mds/overview/#last-but-not-least","title":"Last but not least","text":"<p>\u2b50\ufe0f Like, share, and don\u2019t forget to subscribe to the channel !</p>"},{"location":"mds/sockets101/","title":"Sockets 101","text":"<p>Because tofu uses sockets under the hood, you still need to understand:</p> <ul> <li>the addressing scheme</li> <li>the correct order of creating sockets</li> <li>the difference between client and server sides</li> <li>socket tuning</li> </ul>"},{"location":"mds/sockets101/#what-is-a-socket","title":"What is a Socket?","text":"<p>A socket is a software endpoint. It lets two programs communicate. This can be on the same computer or across a network.</p>"},{"location":"mds/sockets101/#stream-oriented-sockets","title":"Stream-Oriented Sockets","text":"<p>These use a reliable, ordered, connection-based protocol. TCP (Transmission Control Protocol) is the main example. Data is sent as a continuous stream of bytes. It guarantees all data arrives correctly.</p>"},{"location":"mds/sockets101/#socket-families-protocols","title":"Socket Families (Protocols)","text":"<p>Sockets use different communication protocol families.</p>"},{"location":"mds/sockets101/#1-tcpip-sockets","title":"1. TCP/IP Sockets","text":"<p>For network communication. Uses IP addresses to identify machines. TCP/IP is the foundation of the internet.</p>"},{"location":"mds/sockets101/#2-unix-domain-sockets-uds","title":"2. Unix Domain Sockets (UDS)","text":"<p>For local communication only. Works on the same computer. No network hardware needed. Often faster than TCP/IP for local processes.</p>"},{"location":"mds/sockets101/#socket-operations","title":"Socket Operations","text":"<p>Sockets follow this lifecycle.</p>"},{"location":"mds/sockets101/#1-create","title":"1. Create","text":"<p>First step: create the socket. This reserves system resources. Gives you a handle (file descriptor) for later use.</p>"},{"location":"mds/sockets101/#2-client-connect","title":"2. Client: Connect","text":"<p>Client uses connect(). Links its socket to the server's address. If successful, communication stream opens.</p>"},{"location":"mds/sockets101/#3-server-listen-and-accept","title":"3. Server: Listen and Accept","text":"<p>Server waits for client connections.</p> <ul> <li>Bind: Attach socket to specific local address.</li> <li>Listen: Wait for incoming connection requests.</li> <li>Accept: When client connects, accept() returns.<ul> <li>Creates a second, new socket.</li> <li>Original socket stays as listener.</li> <li>New socket handles data with that client.</li> </ul> </li> </ul>"},{"location":"mds/sockets101/#4-disconnect-close","title":"4. Disconnect (Close)","text":"<p>Communication ends when socket closes.</p> <ul> <li>Graceful close: Clean shutdown, data sent completely.</li> <li>Non-graceful close: Sudden close, data may be lost.</li> </ul>"},{"location":"mds/sockets101/#addresses-tcpip","title":"Addresses - TCP/IP","text":"<p>TCP/IP addresses combine IP address + port number.</p>"},{"location":"mds/sockets101/#server-address-bind","title":"Server Address (Bind)","text":"<p>Server binds to local IP address. Uses fixed port number (22, 80, 443).</p> <p>Specific Adapter: 192.168.1.10:80 - Only accepts connections to that IP.</p> <p>All Adapters (Wildcard): 0.0.0.0:8080 - Listens on all network cards on port 8080.</p>"},{"location":"mds/sockets101/#client-address-connect","title":"Client Address (Connect)","text":"<p>Client uses server's IP or hostname + port. Client gets temporary ephemeral port automatically.</p> <p>Example: Client connects to 192.168.1.10:80 Client local: 10.0.0.5:54321 (ephemeral port)</p>"},{"location":"mds/sockets101/#addresses-unix-domain-sockets-uds","title":"Addresses - Unix Domain Sockets (UDS)","text":"<p>No IP addresses or ports.</p> <p>Uses file system path instead. Example: /tmp/service.sock</p> <p>Server binds to path. Client connects to same path.</p>"},{"location":"mds/sockets101/#how-linux-tracks-sockets","title":"How Linux Tracks Sockets","text":""},{"location":"mds/sockets101/#file-descriptor-fd-socket-handle","title":"File Descriptor (FD) = Socket Handle","text":"<p>Every socket gets a small number (FD). Like an ID for your program. Example: socket_fd = 5</p> <p>Use it to read/write/close: send(5, ...), close(5)</p>"},{"location":"mds/sockets101/#fd-is-unique-only-inside-one-process","title":"FD is unique only inside one process","text":"<p>Process A: FD=3 Process B: FD=3 (different socket) OS uses (PID + FD) to identify real socket.</p>"},{"location":"mds/sockets101/#socket-tuning-with-options","title":"Socket tuning with options","text":""},{"location":"mds/sockets101/#reuse-port-quickly-so_reuseaddr-option","title":"Reuse Port Quickly - SO_REUSEADDR option","text":"<p>When TCP connection closes, socket enters TIME_WAIT state. Lasts 1-4 minutes.</p> <p>During TIME_WAIT: - System blocks new program from using same port.</p> <p>Problems: - Cannot restart server fast. - Testing slow (start/stop many times).</p> <p>SO_REUSEADDR fixes this.</p> <p>tofu sets SO_REUSEADDR on all listening sockets.</p> <p>Result: Every new tofu TCP server uses same port immediately.</p>"},{"location":"mds/sockets101/#socket-closing-modes-so_linger-option","title":"Socket closing modes - SO_LINGER option","text":"<p>Normal socket close:</p> <ul> <li>close() returns right away</li> <li>System sends remaining data in background (graceful close)</li> </ul> <p>SO_LINGER changes this.</p> <p>tofu uses only non-graceful (hard) close:</p> <ul> <li>close() returns immediately</li> <li>Connection closes instantly (reset)</li> <li>All unsent data discarded</li> </ul> <p>Get graceful close using other tofu features instead.</p>"}]}